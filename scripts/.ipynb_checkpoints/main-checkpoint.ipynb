{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import scale\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats.stats import pearsonr   \n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "import math\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import time\n",
    "from sklearn.metrics import r2_score\n",
    "np.random.seed(7)\n",
    "from torchvision import transforms, utils\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "solar_gains = pd.read_csv(r'C:\\Users\\jrv966\\Documents\\GitHub\\surrogate_models\\data\\energy_demands\\thermal_losses.csv')\n",
    "# inputs_solar = pd.read_csv(r'C:\\Users\\jrv966\\Documents\\GitHub\\surrogate_models\\data\\inputs\\inputs_thermal.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Copying data to numpy arrays\n",
    "# X_train = np.array(inputs_solar.loc[:,['height',' Ta','perimeter','area','t_sp', 'n_inf','walls_uvalue', 'floor_uvalue', 'roof_uvalue','windows_uvalue','walls_glazing_ratio']].values)\n",
    "# X_train = np.array(inputs_solar.loc[:,['G_Dh','G_Bn','RR','N','height','perimeter','aspect_ratio','walls_glazing_ratio','gvalue','blinds_cutoff']].values)\n",
    "y_train = np.array(solar_gains.loc[:,'Qs-Qi(Wh)':].values)\n",
    "\n",
    "#X_train = np.array(inputs_solar.loc[:,'G_Dh':].values)\n",
    "# X_train = np.array(inputs_solar.loc[:,['G_Dh','G_Bn','RR','N','height','perimeter','aspect_ratio','walls_glazing_ratio','gvalue','blinds_cutoff']].values)\n",
    "# y_train = np.array(solar_gains.loc[:,'Qs-Qi(Wh)':].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "solar_gains = None\n",
    "inputs_solar = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scaling the data (substracting mean and dividing by the standard deviation)\n",
    "X_train = np.divide((X_train-X_train.mean(axis=0)),(X_train.std(axis=0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SPLIT DATA FROM THE ORIGINAL TRAINING DATA INTO TEST AND TRAINING SET\n",
    "X_train, _, y_train, _ = train_test_split(X_train, y_train, test_size=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-39-f7df3fa5946a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#LINEAR REGRESSION - USED AS BASELINE\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mlinear_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLinearRegression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlinear_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mmean_squared_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_test' is not defined"
     ]
    }
   ],
   "source": [
    "#LINEAR REGRESSION - USED AS BASELINE\n",
    "linear_model = LinearRegression().fit(X_train,y_train)\n",
    "y_pred = linear_model.predict(X_test)\n",
    "mean_squared_error(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extremely randomized trees\n",
    "# y_train = np.reshape(y_train,(y_train.shape[0],1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fit the model and keep track of the training time\n",
    "start = time.time()\n",
    "etr = ExtraTreesRegressor(n_estimators = 20,max_features = 15, min_samples_split=2, n_jobs=10).fit(X_train, y_train.ravel())\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluate the error on the test set\n",
    "y_pred_etr = etr.predict(X_test)\n",
    "mse_ert = mean_squared_error(y_test,y_pred_etr)\n",
    "r_score = r2_score(y_test,y_pred_etr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "#Fit the model and keep track of the training time\n",
    "start = time.time()\n",
    "decision_tree = tree.DecisionTreeRegressor()\n",
    "decision_tree = decision_tree.fit(X_train, y_train.ravel())\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from treeinterpreter import treeinterpreter as ti\n",
    "dt_reg_pred, dt_reg_bias, dt_reg_contrib = ti.predict(decision_tree, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluate the error on the test set\n",
    "y_pred_dt = decision_tree.predict(X_test)\n",
    "mse_dt = mean_squared_error(y_test,y_pred_dt)\n",
    "r_score_dt = r2_score(y_test,y_pred_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_score_dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# from sklearn.externals import joblib \n",
    "\n",
    "# pkl_filename = r'C:\\Users\\jrv966\\Documents\\GitHub\\surrogate_models\\results\\ml_models\\extremely_rand_trees.pkl'\n",
    "  \n",
    "# # Save the model as a pickle in a file \n",
    "# joblib.dump(etr, pkl_filename) \n",
    "  \n",
    "# Load the model from the file \n",
    "# knn_from_joblib = joblib.load('filename.pkl')  \n",
    "  \n",
    "# Use the loaded model to make predictions \n",
    "# knn_from_joblib.predict(X_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, input_shape, output_shape):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_shape[1], 11)\n",
    "        self.bn1 = nn.BatchNorm1d(num_features=11)\n",
    "        self.fc2 = nn.Linear(11,6)\n",
    "        self.bn2 = nn.BatchNorm1d(num_features=6)\n",
    "        self.fc3 = nn.Linear(6, output_shape[1])\n",
    "        self.Dropout = nn.Dropout(p=0.0)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out = self.Dropout(F.relu(self.bn1(self.fc1(x)))) + residual\n",
    "        out = self.Dropout(F.relu(self.bn2(self.fc2(out))))\n",
    "        return self.fc3(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cpu'\n",
    "net = Net(X_train.shape, y_train.shape).to(device)\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.02, weight_decay=1e-5)\n",
    "criterion = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_torch = torch.tensor(X_train, device='cpu').float()\n",
    "y_train_torch = torch.tensor(y_train, device='cpu').float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 239062335488.0 0.013578623075315321 1.7697327653566997\n",
      "1 223289753600.0 0.06056986734741987 3.531670848528544\n",
      "2 204805652480.0 0.12767765454418956 5.318526951471965\n",
      "3 170473996288.0 0.21179731770964028 7.110072191556295\n",
      "4 183508697088.0 0.28497549378943743 8.918083314100901\n",
      "5 120495112192.0 0.4017844233534841 10.657733790079753\n",
      "6 144310059008.0 0.4572291060026211 12.843443703651428\n",
      "7 110889484288.0 0.5511004843547952 15.08269767363866\n",
      "8 80459718656.0 0.651689451781994 16.97549532254537\n",
      "9 84551639040.0 0.6901276523700446 18.861136730511983\n",
      "10 43876069376.0 0.7991677732215591 20.71559507449468\n",
      "11 41504780288.0 0.8161449144587951 22.563134984175363\n",
      "12 40174637056.0 0.8525191332419908 24.549057281017305\n",
      "13 27284756480.0 0.8898286822491506 26.444745842615763\n",
      "14 23912667136.0 0.9040027114957401 28.337603950500487\n",
      "15 22163931136.0 0.9044259199468105 30.171390624841056\n",
      "16 23435096064.0 0.8833382464098745 32.02306255896886\n",
      "17 22432645120.0 0.9047411986703707 33.986376694838206\n",
      "18 20339976192.0 0.9146448976486948 35.8878123442332\n",
      "19 18085273600.0 0.9146252672283169 37.78418320417404\n",
      "20 17492367360.0 0.9246805642084357 39.6554415345192\n",
      "21 18891806720.0 0.9219331330145506 41.522278130054474\n",
      "22 17014073344.0 0.9209425652192961 43.3076064268748\n",
      "23 18840250368.0 0.9197457774994948 45.093394068876904\n",
      "24 17136075776.0 0.9330569624256537 46.949388881524406\n",
      "25 16442886144.0 0.9206168785669802 49.04405474265416\n",
      "26 16282114048.0 0.9295714391930235 51.19034224351247\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-51bf10d909d5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m             \u001b[0my_train_batch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my_train_torch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbatch_indexes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m             \u001b[0mX_train_batch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_train_torch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbatch_indexes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m             \u001b[0my_train_batch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my_train_torch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbatch_indexes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "epochs = 60\n",
    "iterations = 1000\n",
    "lambda1 = 60000\n",
    "batch_size = int(y_train.shape[0]/iterations)\n",
    "start = time.time()\n",
    "for epoch  in range(epochs):\n",
    "    batch_indexes = np.random.choice(X_train.shape[0], X_train.shape[0], replace=False)\n",
    "    for i in range(iterations):\n",
    "        if i == iterations-1:\n",
    "            X_train_batch = X_train_torch[batch_indexes[i*batch_size:-1]]\n",
    "            y_train_batch = y_train_torch[batch_indexes[i*batch_size:-1]]\n",
    "        else:\n",
    "            X_train_batch = X_train_torch[batch_indexes[i*batch_size:i*batch_size+batch_size]]\n",
    "            y_train_batch = y_train_torch[batch_indexes[i*batch_size:i*batch_size+batch_size]]\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        y_pred = net(X_train_batch)\n",
    "\n",
    "        regularization_loss = 0\n",
    "        for param in net.parameters():\n",
    "            regularization_loss += (torch.sum(torch.abs(param)))\n",
    "\n",
    "        loss = criterion(y_pred, y_train_batch) # lambda1*regularization_loss\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    PATH = r'C:\\Users\\jrv966\\Documents\\GitHub\\surrogate_models\\results\\ml_models\\thermal\\dnn'+str(epoch)\n",
    "    torch.save(net.state_dict(), PATH)\n",
    "    print(epoch, loss.item(), r2_score(y_train_batch.data.numpy(),y_pred.data.numpy()), (time.time() - start)/60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "regularization_loss = 0\n",
    "for param in net.parameters():\n",
    "    regularization_loss += (torch.sum(torch.abs(param)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2656372., grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.2*1091034752.0/regularization_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1188.4360, grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regularization_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.4482e+11, grad_fn=<MseLossBackward>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4120057.5549254054"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.02*2.4482e+11/1188.43"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
